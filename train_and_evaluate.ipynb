{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06749b7",
   "metadata": {},
   "source": [
    "### 1. Framework imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf706ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "c:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import threading\n",
    "import pynvml\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset, dataset_resolver\n",
    "\n",
    "#logging.getLogger(\"pykeen\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261de46",
   "metadata": {},
   "source": [
    "### 2. Defining function for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_monitor(stop_event, interval=1.0, device_index=0, stats=None):\n",
    "    \"\"\"Thread para monitorar consumo de GPU durante o treino.\"\"\"\n",
    "    \n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)\n",
    "    while not stop_event.is_set():\n",
    "        mem = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # W\n",
    "        stats[\"mem_used\"].append(mem.used / 1024**2)  # MB\n",
    "        stats[\"util\"].append(util.gpu)  # %\n",
    "        stats[\"power\"].append(power)  # W\n",
    "        time.sleep(interval)\n",
    "\n",
    "def run_experiment(model_name: str, dataset_name: str, epochs: int = 100,\n",
    "                   batch_size: int = 256, test_batch_size = 256, device: str = \"cuda\",\n",
    "                   inference_batch_size: int = 1, seed: int = 42,\n",
    "                   n_tests: int = 1, verbose: bool = True, slice_size = None,\n",
    "                   gpu_index: int = 0, monitor_interval: float = 0.1) -> pd.DataFrame:\n",
    "\n",
    "    metrics = []\n",
    "    models = []\n",
    "    pynvml.nvmlInit()\n",
    "    for i in range(n_tests):\n",
    "        stats = {\"mem_used\": [], \"util\": [], \"power\": []}\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(\n",
    "            target=gpu_monitor, args=(stop_event, monitor_interval, gpu_index, stats)\n",
    "        )\n",
    "        seed = seed + 1\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # --- iniciar monitoramento GPU\n",
    "        monitor_thread.start()\n",
    "\n",
    "        dataset = get_dataset(dataset=dataset_name)\n",
    "\n",
    "        # --- Treino + avaliação do PyKEEN\n",
    "        result = pipeline(\n",
    "            model=model_name,\n",
    "            dataset=dataset_name,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            random_seed=seed, \n",
    "            training_kwargs=dict(batch_size=batch_size, use_tqdm_batch=False,), # sampler=\"schlichtkrull\" ISSO AQUI FAZ O NEGOCIO RODAR 10 VEZES MAIS LENTO!!!\n",
    "            negative_sampler = \"basic\",\n",
    "            negative_sampler_kwargs=dict(\n",
    "            filtered=True),\n",
    "            use_tqdm=verbose,\n",
    "            evaluation_kwargs=dict(slice_size = slice_size)\n",
    "        )\n",
    "\n",
    "        # --- parar monitoramento\n",
    "        stop_event.set()\n",
    "        monitor_thread.join()\n",
    "\n",
    "        # --- estatísticas GPU\n",
    "        avg_mem = sum(stats[\"mem_used\"]) / len(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        peak_mem = max(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        avg_util = sum(stats[\"util\"]) / len(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        peak_util = max(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        avg_power = sum(stats[\"power\"]) / len(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        peak_power = max(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        total_energy_wh = sum(p * monitor_interval for p in stats[\"power\"]) / 3600 if stats[\"power\"] else None\n",
    "\n",
    "        # extrair tempos do pipeline\n",
    "        train_time = getattr(result, \"train_seconds\", None)\n",
    "        eval_time = getattr(result, \"evaluate_seconds\", None)\n",
    "\n",
    "        # métricas do teste\n",
    "        mrr = result.metric_results.get_metric('both.realistic.inverse_harmonic_mean_rank')\n",
    "        hits1 = result.metric_results.get_metric('both.realistic.hits_at_1')\n",
    "        hits3 = result.metric_results.get_metric('both.realistic.hits_at_3')\n",
    "        hits5 = result.metric_results.get_metric('both.realistic.hits_at_5')\n",
    "        hits10 = result.metric_results.get_metric('both.realistic.hits_at_10')\n",
    "\n",
    "         # --- Tempo de inferência pura\n",
    "        dataset = dataset_resolver.lookup(dataset_name)()\n",
    "        triples = dataset.testing.mapped_triples\n",
    "        n_test = int(triples.shape[0]) if hasattr(triples, \"shape\") else len(triples)\n",
    "\n",
    "        model = result.model\n",
    "        device_torch = model.device\n",
    "        # CONVERSÃO ROBUSTA:\n",
    "        if isinstance(triples, torch.Tensor):\n",
    "            triples_tensor = triples.to(device=device_torch, dtype=torch.long)\n",
    "        else:\n",
    "            # as_tensor evita cópia se já for tensor; em numpy -> cria tensor\n",
    "            triples_tensor = torch.as_tensor(triples, dtype=torch.long)\n",
    "            triples_tensor = triples_tensor.to(device=device_torch)\n",
    "\n",
    "        # inferência\n",
    "        with torch.inference_mode():\n",
    "            infer_t0 = time.perf_counter()\n",
    "            for j in range(0, n_test, inference_batch_size):   # use 'j' para não conflitar\n",
    "                batch = triples_tensor[j:j+inference_batch_size]\n",
    "                _ = model.score_hrt(batch)\n",
    "            # sincroniza só se CUDA\n",
    "            if device_torch.type == \"cuda\" and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize(device_torch)\n",
    "            infer_t1 = time.perf_counter()\n",
    "\n",
    "        infer_time = (infer_t1 - infer_t0) / n_test if n_test else None\n",
    "        \n",
    "        # após terminar este experimento (antes do próximo loop):\n",
    "        del batch\n",
    "        del triples_tensor\n",
    "        del model\n",
    "        del result\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            # sincroniza para garantir operações pendentes concluidas\n",
    "            torch.cuda.synchronize()\n",
    "        # --- montar resultado em forma de DataFrame (1 linha)\n",
    "        df = pd.DataFrame([{\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"seed\": seed,\n",
    "            \"epochs\": epochs,\n",
    "            \"train_time\": train_time,\n",
    "            \"eval_time\": eval_time,\n",
    "            \"inference_time\": infer_time,\n",
    "            \"mrr\": mrr,\n",
    "            \"hits@1\": hits1,\n",
    "            \"hits@3\": hits3,\n",
    "            \"hits@5\": hits5,\n",
    "            \"hits@10\": hits10,\n",
    "            \"gpu_mem_avg_MB\": avg_mem,\n",
    "            \"gpu_mem_peak_MB\": peak_mem,\n",
    "            \"gpu_util_avg_%\": avg_util,\n",
    "            \"gpu_util_peak_%\": peak_util,\n",
    "            \"gpu_power_avg_W\": avg_power,\n",
    "            \"gpu_power_peak_W\": peak_power,\n",
    "            \"gpu_energy_Wh\": total_energy_wh,\n",
    "        }])\n",
    "        metrics.append(df)\n",
    "    pynvml.nvmlShutdown()\n",
    "        \n",
    "        \n",
    "    return pd.concat(metrics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e3c3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    # sincroniza para garantir operações pendentes concluidas\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5db96e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.pipeline.api:Using device: cuda\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=True for RGCNRepresentation()\n",
      "INFO:pykeen.nn.message_passing:No num_bases was provided. Using sqrt(num_relations)=8.\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=True for LowRankRepresentation()\n",
      "INFO:pykeen.nn.message_passing:No num_bases was provided. Using sqrt(num_relations)=8.\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=True for LowRankRepresentation()\n",
      "INFO:pykeen.nn.message_passing:No num_bases was provided. Using sqrt(num_relations)=8.\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=True for LowRankRepresentation()\n",
      "INFO:pykeen.nn.message_passing:No num_bases was provided. Using sqrt(num_relations)=8.\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=True for LowRankRepresentation()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.training.training_loop:Using RGCN without graph-based sampling! Please select sampler=\"schlichtkrull\" instead of None.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "WARNING:pykeen.nn.message_passing:Layers RGCNLayer(\n",
      "  (fwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bwd): BasesDecomposition(\n",
      "    (relation_representations): LowRankRepresentation(\n",
      "      (base): Embedding(\n",
      "        (_embeddings): Embedding(8, 250000)\n",
      "      )\n",
      "      (weight): Embedding(\n",
      "        (_embeddings): Embedding(55, 8)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (self_loop): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") has parameters, but no reset_parameters.\n",
      "Training epochs on cuda:0: 100%|██████████| 1/1 [00:00<00:00,  4.08epoch/s, loss=1, prev_loss=nan]\n",
      "Evaluating on cuda:0: 100%|██████████| 201/201 [00:00<00:00, 2.17ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.10s seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>eval_time</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>gpu_mem_avg_MB</th>\n",
       "      <th>gpu_mem_peak_MB</th>\n",
       "      <th>gpu_util_avg_%</th>\n",
       "      <th>gpu_util_peak_%</th>\n",
       "      <th>gpu_power_avg_W</th>\n",
       "      <th>gpu_power_peak_W</th>\n",
       "      <th>gpu_energy_Wh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-GCN</td>\n",
       "      <td>Nations</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643891</td>\n",
       "      <td>0.103598</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.396227</td>\n",
       "      <td>0.191542</td>\n",
       "      <td>0.470149</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.937811</td>\n",
       "      <td>2166.924479</td>\n",
       "      <td>2172.257812</td>\n",
       "      <td>10.777778</td>\n",
       "      <td>13</td>\n",
       "      <td>10.923444</td>\n",
       "      <td>15.647</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  dataset  seed  epochs  train_time  eval_time  inference_time  \\\n",
       "0  R-GCN  Nations     2       1    0.643891   0.103598        0.000733   \n",
       "\n",
       "        mrr    hits@1    hits@3    hits@5   hits@10  gpu_mem_avg_MB  \\\n",
       "0  0.396227  0.191542  0.470149  0.656716  0.937811     2166.924479   \n",
       "\n",
       "   gpu_mem_peak_MB  gpu_util_avg_%  gpu_util_peak_%  gpu_power_avg_W  \\\n",
       "0      2172.257812       10.777778               13        10.923444   \n",
       "\n",
       "   gpu_power_peak_W  gpu_energy_Wh  \n",
       "0            15.647       0.002731  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df = run_experiment(model_name=\"R-GCN\", dataset_name=\"Nations\", epochs=1, batch_size=2048, slice_size = 512, device=\"cuda\", seed=1, n_tests = 1, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c8cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The ConvE model should be trained with inverse triples.\n",
      "This can be done by defining the TriplesFactory class with the _create_inverse_triples_ parameter set to true.\n",
      "Training epochs on cuda:0:   0%|          | 0/10 [00:00<?, ?epoch/s]INFO:pykeen.training.training_loop:Dropping last (incomplete) batch each epoch (1/15 (6.67%) batches).\n",
      "Training epochs on cuda:0: 100%|██████████| 10/10 [00:06<00:00,  1.48epoch/s, loss=0.354, prev_loss=0.393]\n",
      "Evaluating on cuda:0:  37%|███▋      | 768/2.10k [03:19<05:44, 3.86triple/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConvE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDBpedia50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, test_batch_size, device, inference_batch_size, seed, n_tests, verbose, slice_size, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     39\u001b[39m dataset = get_dataset(dataset=dataset_name)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# sampler=\"schlichtkrull\" ISSO AQUI FAZ O NEGOCIO RODAR 10 VEZES MAIS LENTO!!!\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbasic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     57\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1556\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m   1540\u001b[39m stopper_instance, configuration, losses, train_seconds = _handle_training(\n\u001b[32m   1541\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1542\u001b[39m     training=training,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1553\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1554\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m metric_results, evaluate_seconds = \u001b[43m_handle_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResult(\n\u001b[32m   1574\u001b[39m     random_seed=_random_seed,\n\u001b[32m   1575\u001b[39m     model=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1584\u001b[39m     evaluate_seconds=evaluate_seconds,\n\u001b[32m   1585\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1284\u001b[39m, in \u001b[36m_handle_evaluation\u001b[39m\u001b[34m(_result_tracker, model_instance, evaluator_instance, stopper_instance, training, testing, validation, training_kwargs, evaluation_kwargs, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1275\u001b[39m _result_tracker.log_params(\n\u001b[32m   1276\u001b[39m     params=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   1277\u001b[39m         evaluation_kwargs={\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     )\n\u001b[32m   1282\u001b[39m )\n\u001b[32m   1283\u001b[39m evaluate_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m metric_results = \u001b[43mevaluator_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m evaluate_end_time = time.time() - evaluate_start_time\n\u001b[32m   1288\u001b[39m step = training_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:293\u001b[39m, in \u001b[36mEvaluator.evaluate\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets)\u001b[39m\n\u001b[32m    291\u001b[39m     tqdm_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_on_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:370\u001b[39m, in \u001b[36mEvaluator._evaluate_on_device\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, all_pos_triples, targets, tqdm_kwargs, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# Show progressbar\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    360\u001b[39m     **ChainMap(\n\u001b[32m    361\u001b[39m         \u001b[38;5;28mdict\u001b[39m(tqdm_kwargs),\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     )\n\u001b[32m    369\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# note: we provide the *maximum* batch and slice size here; it is reduced if necessary\u001b[39;49;00m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# kwargs\u001b[39;49;00m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch_max_mem\\api.py:494\u001b[39m, in \u001b[36mMemoryUtilizationMaximizer.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     values = \u001b[38;5;28mtuple\u001b[39m(bound.arguments[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameter_names)\n\u001b[32m    493\u001b[39m kwargs.update(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.parameter_names, values))\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m result, \u001b[38;5;28mself\u001b[39m.parameter_value[h] = \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch_max_mem\\api.py:357\u001b[39m, in \u001b[36mmaximize_memory_utilization_decorator.<locals>.decorator_maximize_memory_utilization.<locals>.wrapper_maximize_memory_utilization\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m bound_arguments.arguments.update(p_kwargs)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mtuple\u001b[39m(max_values)\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (torch.cuda.OutOfMemoryError, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    359\u001b[39m     \u001b[38;5;66;03m# raise errors unrelated to out-of-memory\u001b[39;00m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_oom_error(error):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:482\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(evaluator, mapped_triples, batch_size, slice_size, progress_bar, targets, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     relation_filter = \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# update progress bar with actual batch size\u001b[39;00m\n\u001b[32m    491\u001b[39m progress_bar.update(batch.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:626\u001b[39m, in \u001b[36m_evaluate_batch\u001b[39m\u001b[34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[39m\n\u001b[32m    620\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    621\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf filtering_necessary of positive_masks_required is True, all_pos_triples has to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    622\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprovided, but is None.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    623\u001b[39m         )\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# Create filter\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     positive_filter, relation_filter = \u001b[43mcreate_sparse_positive_filter_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     positive_filter = relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:536\u001b[39m, in \u001b[36mcreate_sparse_positive_filter_\u001b[39m\u001b[34m(hrt_batch, all_pos_triples, relation_filter, filter_col)\u001b[39m\n\u001b[32m    533\u001b[39m entities = hrt_batch[:, other_col : other_col + \u001b[32m1\u001b[39m]\n\u001b[32m    535\u001b[39m entity_filter_test = (all_pos_triples[:, other_col : other_col + \u001b[32m1\u001b[39m]).view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m) == entities\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m filter_batch = \u001b[43m(\u001b[49m\u001b[43mentity_filter_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m filter_batch[:, \u001b[32m1\u001b[39m] = all_pos_triples[:, filter_col : filter_col + \u001b[32m1\u001b[39m].view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)[:, filter_batch[:, \u001b[32m1\u001b[39m]]\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filter_batch, relation_filter\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df = run_experiment(model_name=\"ConvE\", dataset_name=\"DBpedia50\", batch_size=2048, slice_size=512, epochs=10, device=\"cuda\", seed=1, n_tests = 5, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcde904",
   "metadata": {},
   "source": [
    "### 3. Definir modelos e datasets a serem avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8463107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ConvE on DBPedia50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/dbpedia50/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.pipeline.api:Using device: cuda\n",
      "WARNING:pykeen.models.unimodal.conv_e:\n",
      "The ConvE model should be trained with inverse triples.\n",
      "This can be done by defining the TriplesFactory class with the _create_inverse_triples_ parameter set to true.\n",
      "INFO:pykeen.nn.modules:Resolving None * None * None = 200.\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding()\n",
      "Training epochs on cuda:0:   0%|          | 0/10 [00:00<?, ?epoch/s]INFO:pykeen.training.training_loop:Dropping last (incomplete) batch each epoch (1/15 (6.67%) batches).\n",
      "Training epochs on cuda:0: 100%|██████████| 10/10 [00:06<00:00,  1.44epoch/s, loss=0.351, prev_loss=0.39]\n",
      "Evaluating on cuda:0:   3%|▎         | 72.0/2.10k [00:30<14:12, 2.37triple/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     df = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     final_df = pd.concat([final_df, df], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m#with open(output_dir + 'model_'+model_name+'_'+dataset+'.pkl', 'wb') as f:\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m#    pickle.dump(model, f)\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m#del model\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, test_batch_size, device, inference_batch_size, seed, n_tests, verbose, slice_size, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     39\u001b[39m dataset = get_dataset(dataset=dataset_name)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# sampler=\"schlichtkrull\" ISSO AQUI FAZ O NEGOCIO RODAR 10 VEZES MAIS LENTO!!!\u001b[39;49;00m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbasic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnegative_sampler_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     57\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1556\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m   1540\u001b[39m stopper_instance, configuration, losses, train_seconds = _handle_training(\n\u001b[32m   1541\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1542\u001b[39m     training=training,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1553\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1554\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m metric_results, evaluate_seconds = \u001b[43m_handle_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResult(\n\u001b[32m   1574\u001b[39m     random_seed=_random_seed,\n\u001b[32m   1575\u001b[39m     model=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1584\u001b[39m     evaluate_seconds=evaluate_seconds,\n\u001b[32m   1585\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1284\u001b[39m, in \u001b[36m_handle_evaluation\u001b[39m\u001b[34m(_result_tracker, model_instance, evaluator_instance, stopper_instance, training, testing, validation, training_kwargs, evaluation_kwargs, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1275\u001b[39m _result_tracker.log_params(\n\u001b[32m   1276\u001b[39m     params=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   1277\u001b[39m         evaluation_kwargs={\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     )\n\u001b[32m   1282\u001b[39m )\n\u001b[32m   1283\u001b[39m evaluate_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m metric_results = \u001b[43mevaluator_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m evaluate_end_time = time.time() - evaluate_start_time\n\u001b[32m   1288\u001b[39m step = training_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:293\u001b[39m, in \u001b[36mEvaluator.evaluate\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets)\u001b[39m\n\u001b[32m    291\u001b[39m     tqdm_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_on_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:370\u001b[39m, in \u001b[36mEvaluator._evaluate_on_device\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, all_pos_triples, targets, tqdm_kwargs, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# Show progressbar\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    360\u001b[39m     **ChainMap(\n\u001b[32m    361\u001b[39m         \u001b[38;5;28mdict\u001b[39m(tqdm_kwargs),\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     )\n\u001b[32m    369\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# note: we provide the *maximum* batch and slice size here; it is reduced if necessary\u001b[39;49;00m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# kwargs\u001b[39;49;00m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch_max_mem\\api.py:494\u001b[39m, in \u001b[36mMemoryUtilizationMaximizer.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     values = \u001b[38;5;28mtuple\u001b[39m(bound.arguments[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameter_names)\n\u001b[32m    493\u001b[39m kwargs.update(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.parameter_names, values))\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m result, \u001b[38;5;28mself\u001b[39m.parameter_value[h] = \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch_max_mem\\api.py:357\u001b[39m, in \u001b[36mmaximize_memory_utilization_decorator.<locals>.decorator_maximize_memory_utilization.<locals>.wrapper_maximize_memory_utilization\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m bound_arguments.arguments.update(p_kwargs)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mtuple\u001b[39m(max_values)\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (torch.cuda.OutOfMemoryError, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    359\u001b[39m     \u001b[38;5;66;03m# raise errors unrelated to out-of-memory\u001b[39;00m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_oom_error(error):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:482\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(evaluator, mapped_triples, batch_size, slice_size, progress_bar, targets, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     relation_filter = \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# update progress bar with actual batch size\u001b[39;00m\n\u001b[32m    491\u001b[39m progress_bar.update(batch.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:626\u001b[39m, in \u001b[36m_evaluate_batch\u001b[39m\u001b[34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[39m\n\u001b[32m    620\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    621\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf filtering_necessary of positive_masks_required is True, all_pos_triples has to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    622\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprovided, but is None.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    623\u001b[39m         )\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# Create filter\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     positive_filter, relation_filter = \u001b[43mcreate_sparse_positive_filter_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     positive_filter = relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\envs\\perf_2026\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:536\u001b[39m, in \u001b[36mcreate_sparse_positive_filter_\u001b[39m\u001b[34m(hrt_batch, all_pos_triples, relation_filter, filter_col)\u001b[39m\n\u001b[32m    533\u001b[39m entities = hrt_batch[:, other_col : other_col + \u001b[32m1\u001b[39m]\n\u001b[32m    535\u001b[39m entity_filter_test = (all_pos_triples[:, other_col : other_col + \u001b[32m1\u001b[39m]).view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m) == entities\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m filter_batch = \u001b[43m(\u001b[49m\u001b[43mentity_filter_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m filter_batch[:, \u001b[32m1\u001b[39m] = all_pos_triples[:, filter_col : filter_col + \u001b[32m1\u001b[39m].view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)[:, filter_batch[:, \u001b[32m1\u001b[39m]]\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filter_batch, relation_filter\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_names = [\"ConvE\",\"ComplEx\",\"ConvKB\",\"DistMult\",\"TransE\",\"RotatE\",\"R-GCN\"]\n",
    "\n",
    "dataset_names = [ \"DBPedia50\"]\n",
    "final_df = None\n",
    "#models = []\n",
    "output_dir = 'results/'\n",
    "version = 'v07'\n",
    "for dataset in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        print(f\"Running {model_name} on {dataset}\")\n",
    "        df = run_experiment(model_name=model_name, dataset_name=dataset, batch_size=2048, test_batch_size=32, epochs=10, device=\"cuda\", seed=1, n_tests = 1, inference_batch_size=1)\n",
    "        final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        #with open(output_dir + 'model_'+model_name+'_'+dataset+'.pkl', 'wb') as f:\n",
    "        #    pickle.dump(model, f)\n",
    "        #del model\n",
    "        final_df.to_csv(output_dir + 'results_' + version + '.csv', index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2b8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17f570fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>eval_time</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>gpu_mem_avg_MB</th>\n",
       "      <th>gpu_mem_peak_MB</th>\n",
       "      <th>gpu_util_avg_%</th>\n",
       "      <th>gpu_util_peak_%</th>\n",
       "      <th>gpu_power_avg_W</th>\n",
       "      <th>gpu_power_peak_W</th>\n",
       "      <th>gpu_energy_Wh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>55.889957</td>\n",
       "      <td>0.049483</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.388256</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>1838.424915</td>\n",
       "      <td>2151.832031</td>\n",
       "      <td>17.493976</td>\n",
       "      <td>37</td>\n",
       "      <td>10.195176</td>\n",
       "      <td>33.216</td>\n",
       "      <td>0.117528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>57.121391</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.392444</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.465174</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>1834.842898</td>\n",
       "      <td>1845.843750</td>\n",
       "      <td>28.345455</td>\n",
       "      <td>39</td>\n",
       "      <td>9.852670</td>\n",
       "      <td>10.285</td>\n",
       "      <td>0.120422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>56.744441</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.426237</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>1832.942903</td>\n",
       "      <td>1842.906250</td>\n",
       "      <td>26.528037</td>\n",
       "      <td>38</td>\n",
       "      <td>9.479516</td>\n",
       "      <td>9.995</td>\n",
       "      <td>0.112701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>56.815753</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.380729</td>\n",
       "      <td>0.161692</td>\n",
       "      <td>0.460199</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>1833.139165</td>\n",
       "      <td>1841.406250</td>\n",
       "      <td>28.376168</td>\n",
       "      <td>39</td>\n",
       "      <td>9.530516</td>\n",
       "      <td>9.903</td>\n",
       "      <td>0.113307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>57.151320</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.403539</td>\n",
       "      <td>0.196517</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>0.699005</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>1831.398524</td>\n",
       "      <td>1841.593750</td>\n",
       "      <td>27.121413</td>\n",
       "      <td>40</td>\n",
       "      <td>9.590554</td>\n",
       "      <td>10.011</td>\n",
       "      <td>0.120681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>3110.717619</td>\n",
       "      <td>49.950012</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>2422.467026</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>25.473166</td>\n",
       "      <td>100</td>\n",
       "      <td>18.702320</td>\n",
       "      <td>57.506</td>\n",
       "      <td>16.242965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>3098.839153</td>\n",
       "      <td>38.222368</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>2441.924034</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>24.595513</td>\n",
       "      <td>100</td>\n",
       "      <td>19.163355</td>\n",
       "      <td>57.917</td>\n",
       "      <td>16.513489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>3102.416068</td>\n",
       "      <td>45.522542</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>2470.003624</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.102796</td>\n",
       "      <td>100</td>\n",
       "      <td>18.975552</td>\n",
       "      <td>57.016</td>\n",
       "      <td>16.403310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>37</td>\n",
       "      <td>100</td>\n",
       "      <td>3107.673787</td>\n",
       "      <td>45.633842</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>2518.112597</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.203248</td>\n",
       "      <td>100</td>\n",
       "      <td>18.874005</td>\n",
       "      <td>56.580</td>\n",
       "      <td>16.335975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>3111.376637</td>\n",
       "      <td>42.630554</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>2552.145205</td>\n",
       "      <td>11938.617188</td>\n",
       "      <td>24.027760</td>\n",
       "      <td>100</td>\n",
       "      <td>18.707008</td>\n",
       "      <td>57.296</td>\n",
       "      <td>16.191955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model    dataset  seed  epochs   train_time  eval_time  inference_time  \\\n",
       "0   ComplEx    Nations     1     100    55.889957   0.049483        0.000453   \n",
       "1   ComplEx    Nations     2     100    57.121391   0.060622        0.000376   \n",
       "2   ComplEx    Nations     4     100    56.744441   0.049614        0.000455   \n",
       "3   ComplEx    Nations     7     100    56.815753   0.055427        0.000489   \n",
       "4   ComplEx    Nations    11     100    57.151320   0.048009        0.000407   \n",
       "..      ...        ...   ...     ...          ...        ...             ...   \n",
       "75  ComplEx  DBpedia50    16     100  3110.717619  49.950012        0.000423   \n",
       "76  ComplEx  DBpedia50    22     100  3098.839153  38.222368        0.000411   \n",
       "77  ComplEx  DBpedia50    29     100  3102.416068  45.522542        0.000430   \n",
       "78  ComplEx  DBpedia50    37     100  3107.673787  45.633842        0.000401   \n",
       "79  ComplEx  DBpedia50    46     100  3111.376637  42.630554        0.000461   \n",
       "\n",
       "         mrr    hits@1    hits@3    hits@5   hits@10  gpu_mem_avg_MB  \\\n",
       "0   0.388256  0.171642  0.462687  0.681592  0.942786     1838.424915   \n",
       "1   0.392444  0.179104  0.465174  0.691542  0.947761     1834.842898   \n",
       "2   0.426237  0.226368  0.504975  0.691542  0.945274     1832.942903   \n",
       "3   0.380729  0.161692  0.460199  0.701493  0.967662     1833.139165   \n",
       "4   0.403539  0.196517  0.472637  0.699005  0.962687     1831.398524   \n",
       "..       ...       ...       ...       ...       ...             ...   \n",
       "75  0.002023  0.000239  0.001909  0.003103  0.004535     2422.467026   \n",
       "76  0.001632  0.000239  0.001193  0.001671  0.003103     2441.924034   \n",
       "77  0.002852  0.000955  0.002625  0.003819  0.005012     2470.003624   \n",
       "78  0.001730  0.000239  0.001193  0.001909  0.003341     2518.112597   \n",
       "79  0.003281  0.001671  0.002625  0.004057  0.005489     2552.145205   \n",
       "\n",
       "    gpu_mem_peak_MB  gpu_util_avg_%  gpu_util_peak_%  gpu_power_avg_W  \\\n",
       "0       2151.832031       17.493976               37        10.195176   \n",
       "1       1845.843750       28.345455               39         9.852670   \n",
       "2       1842.906250       26.528037               38         9.479516   \n",
       "3       1841.406250       28.376168               39         9.530516   \n",
       "4       1841.593750       27.121413               40         9.590554   \n",
       "..              ...             ...              ...              ...   \n",
       "75     11964.398438       25.473166              100        18.702320   \n",
       "76     11964.398438       24.595513              100        19.163355   \n",
       "77     11958.617188       24.102796              100        18.975552   \n",
       "78     11958.617188       24.203248              100        18.874005   \n",
       "79     11938.617188       24.027760              100        18.707008   \n",
       "\n",
       "    gpu_power_peak_W  gpu_energy_Wh  \n",
       "0             33.216       0.117528  \n",
       "1             10.285       0.120422  \n",
       "2              9.995       0.112701  \n",
       "3              9.903       0.113307  \n",
       "4             10.011       0.120681  \n",
       "..               ...            ...  \n",
       "75            57.506      16.242965  \n",
       "76            57.917      16.513489  \n",
       "77            57.016      16.403310  \n",
       "78            56.580      16.335975  \n",
       "79            57.296      16.191955  \n",
       "\n",
       "[80 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a31b4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('results_nations+db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e344cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pkl', 'wb') as file:\n",
    "    # Use pickle.dump() to serialize the model and save it to the file\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d4b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perf_2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
