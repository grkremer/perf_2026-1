{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06749b7",
   "metadata": {},
   "source": [
    "### 1. Framework imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset, dataset_resolver\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261de46",
   "metadata": {},
   "source": [
    "### 2. Defining function for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.datasets.utils:Loading cached preprocessed dataset from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/training\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/testing\n",
      "INFO:pykeen.triples.triples_factory:Loading from file:///C:/Users/grkremer/.data/pykeen/datasets/nations/cache/47DEQpj8HBSa-_TImW-5JCeuQeRkm5NM/validation\n",
      "INFO:pykeen.pipeline.api:Using device: cuda\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding(\n",
      "  (regularizer): LpRegularizer()\n",
      ")\n",
      "INFO:pykeen.nn.representation:Inferred unique=False for Embedding(\n",
      "  (regularizer): LpRegularizer()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e139eef43ca463e8c5bb8b7ce13aaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35727d7c79b4af691f55e7b1ee46a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.06s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00031957341663873016\n",
      "0.0005511323381586009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grkremer\\AppData\\Local\\Temp\\ipykernel_23996\\2324968318.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  triples_tensor = torch.tensor(triples, dtype=torch.long, device=device_torch)\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model_name: str, dataset_name: str, epochs: int = 100,\n",
    "                   batch_size: int = 256, device: str = \"cuda\",\n",
    "                   inference_batch_size: int = 1024, seed: int = 42,\n",
    "                   n_tests: int = 1) -> pd.DataFrame:\n",
    "    metrics = []\n",
    "    models = []\n",
    "    for i in range(n_tests):\n",
    "        seed = seed + i\n",
    "        np.random.seed(seed)\n",
    "        # --- Treino + avaliação do PyKEEN\n",
    "        result = pipeline(\n",
    "            model=model_name,\n",
    "            dataset=dataset_name,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            random_seed=seed,\n",
    "            training_kwargs=dict(batch_size=batch_size, use_tqdm_batch=False),\n",
    "        )\n",
    "\n",
    "        # extrair tempos do pipeline\n",
    "        train_time = getattr(result, \"train_seconds\", None)\n",
    "        eval_time = getattr(result, \"evaluate_seconds\", None)\n",
    "\n",
    "        # métricas do teste\n",
    "        mrr = result.metric_results.get_metric('both.realistic.inverse_harmonic_mean_rank')\n",
    "        hits10 = result.metric_results.get_metric('both.realistic.hits_at_10')\n",
    "\n",
    "        # --- Tempo de inferência pura \n",
    "        dataset = dataset_resolver.lookup(dataset_name)()\n",
    "        triples = dataset.testing.mapped_triples\n",
    "        n_test = triples.shape[0]\n",
    "        print(eval_time/n_test)\n",
    "\n",
    "        model = result.model\n",
    "        device_torch = model.device\n",
    "        triples_tensor = torch.tensor(triples, dtype=torch.long, device=device_torch)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            infer_t0 = time.perf_counter()\n",
    "            for i in range(0, n_test, inference_batch_size):\n",
    "                batch = triples_tensor[i:i+inference_batch_size]\n",
    "                _ = model.score_hrt(batch)\n",
    "            torch.cuda.synchronize()\n",
    "            infer_t1 = time.perf_counter()\n",
    "        infer_time = infer_t1 - infer_t0\n",
    "        infer_time = infer_time/n_test\n",
    "        print(infer_time)\n",
    "\n",
    "        # --- montar resultado em forma de DataFrame (1 linha)\n",
    "        df = pd.DataFrame([{\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"seed\": seed,\n",
    "            \"epochs\": epochs,\n",
    "            \"train_time\": train_time,\n",
    "            \"eval_time\": eval_time,\n",
    "            \"inference_time\": infer_time,\n",
    "            \"mrr\": mrr,\n",
    "            \"hits@10\": hits10,\n",
    "        }])\n",
    "        metrics.append(df)\n",
    "        models.append(result)\n",
    "        \n",
    "        \n",
    "    return pd.concat(metrics, ignore_index=True), models\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    df, models = run_experiment(model_name=\"QuatE\", dataset_name=\"Nations\", epochs=100, device=\"cuda\", seed=1, n_tests = 1, inference_batch_size=1)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a31b4c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineResult(random_seed=1, model=QuatE(\n",
       "  (loss): MarginRankingLoss(\n",
       "    (margin_activation): ReLU()\n",
       "  )\n",
       "  (interaction): QuatEInteraction()\n",
       "  (entity_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (regularizer): LpRegularizer()\n",
       "      (_embeddings): Embedding(14, 400)\n",
       "    )\n",
       "  )\n",
       "  (relation_representations): ModuleList(\n",
       "    (0): Embedding(\n",
       "      (regularizer): LpRegularizer()\n",
       "      (_embeddings): Embedding(55, 400)\n",
       "    )\n",
       "  )\n",
       "  (weight_regularizers): ModuleList()\n",
       "), training=TriplesFactory(num_entities=14, num_relations=55, create_inverse_triples=False, num_triples=1592, path=\"C:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\datasets\\nations\\train.txt\"), training_loop=<pykeen.training.slcwa.SLCWATrainingLoop object at 0x000002B28CA774D0>, losses=[1.0397261551448278, 1.0138601575578963, 1.000816285610199, 0.9945494106837681, 0.9850840057645526, 0.9731997421809605, 0.9576020070484706, 0.942274911063058, 0.9318392361913409, 0.9124024254935128, 0.8972616195678711, 0.8706399628094265, 0.8626177396093097, 0.8449127844401768, 0.818824052810669, 0.8050376517432076, 0.764335572719574, 0.7568135346685138, 0.7273047992161342, 0.6932927114622933, 0.6733044811657497, 0.6569003888538906, 0.6371841600963047, 0.6166066867964608, 0.6099985327039447, 0.5960459453719003, 0.575656533241272, 0.5525577025754111, 0.5642588819776263, 0.5252311868327004, 0.547823999609266, 0.5158737599849701, 0.5223010097231183, 0.4938866751534598, 0.4815726237637656, 0.5031955327306475, 0.4870343165738242, 0.5077072126524789, 0.4716611461980002, 0.44593169007982525, 0.4805350261075156, 0.4732664312635149, 0.46525033031191143, 0.4552322285515921, 0.46059524161475046, 0.46105435490608215, 0.45108427320207867, 0.45922212515558514, 0.42320792589868816, 0.43327867133276804, 0.43657125745500835, 0.4419375147138323, 0.4405472491468702, 0.41557284763881136, 0.4448474645614624, 0.44996712463242666, 0.4322432577610016, 0.42007639152663095, 0.4347282903535025, 0.43656312993594576, 0.4229333017553602, 0.41008528641292025, 0.41007339102881296, 0.434409316096987, 0.4391502950872694, 0.40976288063185556, 0.44306490250996183, 0.4370677854333605, 0.42371409705707, 0.4132696730749948, 0.39703014492988586, 0.38661396503448486, 0.39937855090413776, 0.38269312041146414, 0.38735312649181913, 0.4122145346232823, 0.3939641032900129, 0.4101029804774693, 0.3898924546582358, 0.4295921197959355, 0.43263148835727144, 0.4417243642466409, 0.40212450282914297, 0.4037230227674757, 0.4188370874949864, 0.407027576650892, 0.43875121218817575, 0.41949598704065594, 0.36394038796424866, 0.42161684802600313, 0.4084641805716923, 0.42541632056236267, 0.3868475002901895, 0.4036755859851837, 0.39445784262248446, 0.4065632479531424, 0.41455250126974924, 0.3858532990728106, 0.4130112486226218, 0.41099636469568523], metric_results=<pykeen.evaluation.rank_based_evaluator.RankBasedMetricResults object at 0x000002B25270FED0>, train_seconds=24.017950296401978, evaluate_seconds=0.04842829704284668, stopper=<pykeen.stoppers.stopper.NopStopper object at 0x000002B28A30B750>, configuration={'dataset': 'nations', 'dataset_kwargs': None, 'model': 'QuatE', 'model_kwargs': {'random_seed': 1, 'loss': MarginRankingLoss(\n",
       "  (margin_activation): ReLU()\n",
       "), 'embedding_dim': 100, 'entity_initializer': <function init_quaternions at 0x000002B23C5AE0C0>, 'entity_regularizer': <class 'pykeen.regularizers.LpRegularizer'>, 'entity_regularizer_kwargs': None, 'relation_initializer': <function init_quaternions at 0x000002B23C5AE0C0>, 'relation_regularizer': <class 'pykeen.regularizers.LpRegularizer'>, 'relation_regularizer_kwargs': None, 'relation_normalizer': <function normalize at 0x000002B23C5FEF20>}, 'loss_kwargs': None, 'regularizer_kwargs': None, 'optimizer': 'Adam', 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'decoupled_weight_decay': False}, 'training_loop': 'SLCWATrainingLoop', 'training_loop_kwargs': {}, 'evaluator': 'RankBasedEvaluator', 'evaluator_kwargs': {}, 'batch_size': 256, 'use_tqdm_batch': False, 'num_epochs': 100, 'evaluation_kwargs': {'additional_filter_triples': {'training': {'sha512': '55186f67ee8112c8003519ea87c19bb6b9e110489e6b0a6abeb7a127f2dc9b7195a518f4829d773b82fd47632ac1fe09f6a256cef2469c7dc895210a10919bb4'}, 'validation': {'sha512': '171f020ddad54115ff23a5c7d7143aaf097472f5a76a47b55333ac7c5a522b045cf320b5c0e3842efe005bc017e3e3b1c412532a734195cb1102651babbf631f'}}}}, metadata={}, version='1.11.1', git_hash='UNHASHED')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "82e344cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
