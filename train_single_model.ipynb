{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06749b7",
   "metadata": {},
   "source": [
    "### 1. Framework imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import threading\n",
    "import pynvml\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset, dataset_resolver\n",
    "\n",
    "logging.getLogger(\"pykeen\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261de46",
   "metadata": {},
   "source": [
    "### 2. Defining function for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_monitor(stop_event, interval=1.0, device_index=0, stats=None):\n",
    "    \"\"\"Thread para monitorar consumo de GPU durante o treino.\"\"\"\n",
    "    \n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)\n",
    "    while not stop_event.is_set():\n",
    "        mem = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # W\n",
    "        stats[\"mem_used\"].append(mem.used / 1024**2)  # MB\n",
    "        stats[\"util\"].append(util.gpu)  # %\n",
    "        stats[\"power\"].append(power)  # W\n",
    "        time.sleep(interval)\n",
    "        \n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "\n",
    "def run_experiment(model_name: str, dataset_name: str, epochs: int = 100,\n",
    "                   batch_size: int = 256, device: str = \"cuda\",\n",
    "                   inference_batch_size: int = 1024, seed: int = 42,\n",
    "                   n_tests: int = 1, verbose: bool = True,\n",
    "                   gpu_index: int = 0, monitor_interval: float = 0.1) -> pd.DataFrame:\n",
    "\n",
    "    metrics = []\n",
    "    models = []\n",
    "    pynvml.nvmlInit()\n",
    "    for i in range(n_tests):\n",
    "        stats = {\"mem_used\": [], \"util\": [], \"power\": []}\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(\n",
    "            target=gpu_monitor, args=(stop_event, monitor_interval, gpu_index, stats)\n",
    "        )\n",
    "        seed = seed + 1\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # --- iniciar monitoramento GPU\n",
    "        monitor_thread.start()\n",
    "\n",
    "        # --- Treino + avaliação do PyKEEN\n",
    "        result = pipeline(\n",
    "            model=model_name,\n",
    "            dataset=dataset_name,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            random_seed=seed,\n",
    "            training_kwargs=dict(batch_size=batch_size, use_tqdm_batch=False), # sampler = \n",
    "            use_tqdm=verbose,\n",
    "            evaluation_kwargs=dict(batch_size=256),\n",
    "        )\n",
    "\n",
    "        # --- parar monitoramento\n",
    "        stop_event.set()\n",
    "        monitor_thread.join()\n",
    "\n",
    "        # --- estatísticas GPU\n",
    "        avg_mem = sum(stats[\"mem_used\"]) / len(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        peak_mem = max(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        avg_util = sum(stats[\"util\"]) / len(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        peak_util = max(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        avg_power = sum(stats[\"power\"]) / len(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        peak_power = max(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        total_energy_wh = sum(p * monitor_interval for p in stats[\"power\"]) / 3600 if stats[\"power\"] else None\n",
    "\n",
    "        # extrair tempos do pipeline\n",
    "        train_time = getattr(result, \"train_seconds\", None)\n",
    "        eval_time = getattr(result, \"evaluate_seconds\", None)\n",
    "\n",
    "        # métricas do teste\n",
    "        mrr = result.metric_results.get_metric('both.realistic.inverse_harmonic_mean_rank')\n",
    "        hits1 = result.metric_results.get_metric('both.realistic.hits_at_1')\n",
    "        hits3 = result.metric_results.get_metric('both.realistic.hits_at_3')\n",
    "        hits5 = result.metric_results.get_metric('both.realistic.hits_at_5')\n",
    "        hits10 = result.metric_results.get_metric('both.realistic.hits_at_10')\n",
    "\n",
    "         # --- Tempo de inferência pura\n",
    "        dataset = dataset_resolver.lookup(dataset_name)()\n",
    "        triples = dataset.testing.mapped_triples\n",
    "        n_test = int(triples.shape[0]) if hasattr(triples, \"shape\") else len(triples)\n",
    "\n",
    "        model = result.model\n",
    "        device_torch = model.device\n",
    "        # CONVERSÃO ROBUSTA:\n",
    "        if isinstance(triples, torch.Tensor):\n",
    "            triples_tensor = triples.to(device=device_torch, dtype=torch.long)\n",
    "        else:\n",
    "            # as_tensor evita cópia se já for tensor; em numpy -> cria tensor\n",
    "            triples_tensor = torch.as_tensor(triples, dtype=torch.long)\n",
    "            triples_tensor = triples_tensor.to(device=device_torch)\n",
    "\n",
    "        # inferência\n",
    "        with torch.inference_mode():\n",
    "            infer_t0 = time.perf_counter()\n",
    "            for j in range(0, n_test, inference_batch_size):   # use 'j' para não conflitar\n",
    "                batch = triples_tensor[j:j+inference_batch_size]\n",
    "                _ = model.score_hrt(batch)\n",
    "            # sincroniza só se CUDA\n",
    "            if device_torch.type == \"cuda\" and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize(device_torch)\n",
    "            infer_t1 = time.perf_counter()\n",
    "\n",
    "        infer_time = (infer_t1 - infer_t0) / n_test if n_test else None\n",
    "        \n",
    "        # após terminar este experimento (antes do próximo loop):\n",
    "        del batch\n",
    "        del triples_tensor\n",
    "        del model\n",
    "        del result\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            # sincroniza para garantir operações pendentes concluidas\n",
    "            torch.cuda.synchronize()\n",
    "        # --- montar resultado em forma de DataFrame (1 linha)\n",
    "        df = pd.DataFrame([{\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"seed\": seed,\n",
    "            \"epochs\": epochs,\n",
    "            \"train_time\": train_time,\n",
    "            \"eval_time\": eval_time,\n",
    "            \"inference_time\": infer_time,\n",
    "            \"mrr\": mrr,\n",
    "            \"hits@1\": hits1,\n",
    "            \"hits@3\": hits3,\n",
    "            \"hits@5\": hits5,\n",
    "            \"hits@10\": hits10,\n",
    "            \"gpu_mem_avg_MB\": avg_mem,\n",
    "            \"gpu_mem_peak_MB\": peak_mem,\n",
    "            \"gpu_util_avg_%\": avg_util,\n",
    "            \"gpu_util_peak_%\": peak_util,\n",
    "            \"gpu_power_avg_W\": avg_power,\n",
    "            \"gpu_power_peak_W\": peak_power,\n",
    "            \"gpu_energy_Wh\": total_energy_wh,\n",
    "        }])\n",
    "        metrics.append(df)\n",
    "    pynvml.nvmlShutdown()\n",
    "        \n",
    "        \n",
    "    return pd.concat(metrics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3c3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    # sincroniza para garantir operações pendentes concluidas\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db96e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5468911057c4adea9b80dd4db5d4027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df, models = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConvKB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDBpedia50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, device, inference_batch_size, seed, n_tests, verbose, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     35\u001b[39m monitor_thread.start()\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschlichtkrull\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     49\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1540\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1519\u001b[39m training_loop_instance = _handle_training_loop(\n\u001b[32m   1520\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1521\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m     negative_sampler_kwargs=negative_sampler_kwargs,\n\u001b[32m   1531\u001b[39m )\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m stopper_instance, configuration, losses, train_seconds = \u001b[43m_handle_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m metric_results, evaluate_seconds = _handle_evaluation(\n\u001b[32m   1557\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1558\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1569\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1570\u001b[39m )\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1181\u001b[39m, in \u001b[36m_handle_training\u001b[39m\u001b[34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001b[39m\n\u001b[32m   1179\u001b[39m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[32m   1180\u001b[39m training_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m losses = \u001b[43mtraining_loop_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[32m   1188\u001b[39m training_end_time = time.time() - training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:383\u001b[39m, in \u001b[36mTrainingLoop.train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    380\u001b[39m             temporary_directory = exit_stack.enter_context(TemporaryDirectory())\n\u001b[32m    381\u001b[39m             best_epoch_model_file_path = pathlib.Path(temporary_directory).joinpath(\u001b[33m\"\u001b[39m\u001b[33mbest_model.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[32m    414\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:707\u001b[39m, in \u001b[36mTrainingLoop._train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     batches = train_data_loader\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m epoch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;66;03m# When size probing we don't need the losses\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:453\u001b[39m, in \u001b[36mTrainingLoop._train_epoch\u001b[39m\u001b[34m(self, batches, callbacks, sub_batch_size, label_smoothing, slice_size, epoch, only_size_probing, backward)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Flag to check when to quit the size probing\u001b[39;00m\n\u001b[32m    451\u001b[39m evaluated_once = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# apply callbacks before starting with batch\u001b[39;49;00m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Get batch size of current batch (last batch may be incomplete)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:152\u001b[39m, in \u001b[36mBaseBatchedSLCWAInstances.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[SLCWABatch]:\n\u001b[32m    151\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over batches.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_triple_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.iter_triple_ids\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.subgraph_sample() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubgraph_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:228\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.subgraph_sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# normalize to probabilities\u001b[39;00m\n\u001b[32m    227\u001b[39m     probabilities = weights.float() / weights.sum().float()\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     chosen_vertex = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# sample a start node\u001b[39;00m\n\u001b[32m    231\u001b[39m node_picked[chosen_vertex] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df, models = run_experiment(model_name=\"ConvKB\", dataset_name=\"DBpedia50\", epochs=100, device=\"cuda\", seed=1, n_tests = 1, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c8cd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dd7da0d0b04f53af6bfed38db03784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583f9088bf93478da459e8565bfb326d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/2.10k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConvE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDBpedia50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, device, inference_batch_size, seed, n_tests, verbose, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     35\u001b[39m monitor_thread.start()\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschlichtkrull\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     49\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1556\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m   1540\u001b[39m stopper_instance, configuration, losses, train_seconds = _handle_training(\n\u001b[32m   1541\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1542\u001b[39m     training=training,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1553\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1554\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m metric_results, evaluate_seconds = \u001b[43m_handle_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_testing_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_fallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_validation_when_testing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResult(\n\u001b[32m   1574\u001b[39m     random_seed=_random_seed,\n\u001b[32m   1575\u001b[39m     model=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1584\u001b[39m     evaluate_seconds=evaluate_seconds,\n\u001b[32m   1585\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1284\u001b[39m, in \u001b[36m_handle_evaluation\u001b[39m\u001b[34m(_result_tracker, model_instance, evaluator_instance, stopper_instance, training, testing, validation, training_kwargs, evaluation_kwargs, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1275\u001b[39m _result_tracker.log_params(\n\u001b[32m   1276\u001b[39m     params=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   1277\u001b[39m         evaluation_kwargs={\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     )\n\u001b[32m   1282\u001b[39m )\n\u001b[32m   1283\u001b[39m evaluate_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m metric_results = \u001b[43mevaluator_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m evaluate_end_time = time.time() - evaluate_start_time\n\u001b[32m   1288\u001b[39m step = training_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:293\u001b[39m, in \u001b[36mEvaluator.evaluate\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets)\u001b[39m\n\u001b[32m    291\u001b[39m     tqdm_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdisable\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_on_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrestrict_entities_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:370\u001b[39m, in \u001b[36mEvaluator._evaluate_on_device\u001b[39m\u001b[34m(self, model, mapped_triples, batch_size, slice_size, device, all_pos_triples, targets, tqdm_kwargs, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# Show progressbar\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    360\u001b[39m     **ChainMap(\n\u001b[32m    361\u001b[39m         \u001b[38;5;28mdict\u001b[39m(tqdm_kwargs),\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     )\n\u001b[32m    369\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapped_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# note: we provide the *maximum* batch and slice size here; it is reduced if necessary\u001b[39;49;00m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# kwargs\u001b[39;49;00m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch_max_mem\\api.py:494\u001b[39m, in \u001b[36mMemoryUtilizationMaximizer.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     values = \u001b[38;5;28mtuple\u001b[39m(bound.arguments[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameter_names)\n\u001b[32m    493\u001b[39m kwargs.update(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.parameter_names, values))\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m result, \u001b[38;5;28mself\u001b[39m.parameter_value[h] = \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch_max_mem\\api.py:357\u001b[39m, in \u001b[36mmaximize_memory_utilization_decorator.<locals>.decorator_maximize_memory_utilization.<locals>.wrapper_maximize_memory_utilization\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m bound_arguments.arguments.update(p_kwargs)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mtuple\u001b[39m(max_values)\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (torch.cuda.OutOfMemoryError, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    359\u001b[39m     \u001b[38;5;66;03m# raise errors unrelated to out-of-memory\u001b[39;00m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_oom_error(error):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:482\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(evaluator, mapped_triples, batch_size, slice_size, progress_bar, targets, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     relation_filter = \u001b[43m_evaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# update progress bar with actual batch size\u001b[39;00m\n\u001b[32m    491\u001b[39m progress_bar.update(batch.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:626\u001b[39m, in \u001b[36m_evaluate_batch\u001b[39m\u001b[34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001b[39m\n\u001b[32m    620\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    621\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf filtering_necessary of positive_masks_required is True, all_pos_triples has to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    622\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprovided, but is None.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    623\u001b[39m         )\n\u001b[32m    625\u001b[39m     \u001b[38;5;66;03m# Create filter\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     positive_filter, relation_filter = \u001b[43mcreate_sparse_positive_filter_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhrt_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_pos_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     positive_filter = relation_filter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\evaluation\\evaluator.py:536\u001b[39m, in \u001b[36mcreate_sparse_positive_filter_\u001b[39m\u001b[34m(hrt_batch, all_pos_triples, relation_filter, filter_col)\u001b[39m\n\u001b[32m    533\u001b[39m entities = hrt_batch[:, other_col : other_col + \u001b[32m1\u001b[39m]\n\u001b[32m    535\u001b[39m entity_filter_test = (all_pos_triples[:, other_col : other_col + \u001b[32m1\u001b[39m]).view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m) == entities\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m filter_batch = \u001b[43m(\u001b[49m\u001b[43mentity_filter_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelation_filter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m filter_batch[:, \u001b[32m1\u001b[39m] = all_pos_triples[:, filter_col : filter_col + \u001b[32m1\u001b[39m].view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)[:, filter_batch[:, \u001b[32m1\u001b[39m]]\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m filter_batch, relation_filter\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df = run_experiment(model_name=\"ConvE\", dataset_name=\"DBpedia50\", batch_size=2048, epochs=10, device=\"cuda\", seed=1, n_tests = 5, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcde904",
   "metadata": {},
   "source": [
    "### 3. Definir modelos e datasets a serem avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8463107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ConvE on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104937d74b4b4291bd386aa64814b80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e936c9dcc434c8699a708e6305f6ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c312d33be0174f7396b17f73f92d0505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf8d41559294d4cb94fd04c290a22e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d970d51197d4855bb22a28fd64f1d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e99233019b7426bbe7995bd9f5ac6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c591ee806ad46378c90aa79cef19fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d2d87af18947d782c27865b74317d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c10c1a6873a487b9ea7f8604eb71c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d96fe1b7f1490db6e381c487717c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ComplEx on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab2896517224ad2a7dcd10d1e2ddcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b41e4d5213426daef95bfe027c4c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f6d34d07c047039226eb2b027bc3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3204aaae1041368fa216afea75b051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dae85ccfac648ed8764c4b35fd1bfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef132fc92864a718086d22b006dec19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe2cab6a7d74008b061ae7a4a81f7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9890924a805c410da4c4d4ae1f59c742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50930f07176d4818bac7dc52ddedded5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498270a39422428fb027f88ac589c9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ConvKB on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b81d96b9d4b4685ba972fffe7e08854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553476f2cb0f41c18725d3a6abb4dd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b76770605004913ae8938b9b30276c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1456d78082a44cbba639834cb9005624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445b912b58b14c098a9fa58d9c5246a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d0ace216c428fb58beea84224f024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b814a8ba30bc41a79eb79e63c5424f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e5be33b8384b44958b8825847fab6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d8251e500c49aea337e9798db856d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe46d85501f844c88a0c25fdf773fdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DistMult on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691556ffe23c433e8e1440541f05fa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd522ace9f14e0ab0d1f76fd65d3599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da1a6dd345e4395bd83820580a10612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d6274a461141839e2afe87f4cc2799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea9d8ae9c114ed8a5f037a23740d70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e65f0da76d24c2cbc2926997f0ff93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a8dbbb14954426967ca4224112cab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e77c652290a47a9bf4c6cd9454df3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd331a50bb1468eb8d4e99451c382f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14581f0928ed4b02a962bd5e863590c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TransE on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e558c819664c03b27cf81990ba2857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2eb313bac94c2b9c5663278f4b8431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b8826cd34e478a8667b2de69abbc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce615be2be46e0af8d3ea17f4f95c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9e8d4fb6be48a6823f0e13a8b834b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148abf1af7b148bc89b5ad72dbb43a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efb203846364690a4ab004ecd015f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8bcb027278455ca583c0dd1907b3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a8aba2a20041ec8cb6fed249f1da91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff1376b24bb433eae9f157f52a90139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RotatE on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0953d42fc724199ba0645e8cf44b4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f7c06be9dd4c0ba2389bacca5dd2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c37bd36d764266bee84c42a90a695b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045294b80de54802a43a150478061b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7f4be8416f4efd9d51e653a5e4adc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ccdaa7bae846a79b8c513761253978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3f059c2860417ebbb9d56ca731847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454f4dec7fc149cd97588d63ea691e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9645a3dff2a345e0807825920ae5b569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d707a8fa5946f88d8ec0f455a21876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running R-GCN on Nations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085d8b06a4a64eab99c0a5229959bd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1721a35638450da1be19b512285ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3045e0e8764b8288a7b51e38bc0377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb31456bf24264a540a116194a52f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b835b833024f088fa6d1c9a1d77267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc5ea813d2a4be791bc85c14d5b9867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d7446b6fd34194be1a8ae97a2ec2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe92131ca549b190735eb9b9a73096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4e5bd423b3480dbc2222813e453dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efc6a831dc64770b35d05b1bae50eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/201 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"ConvE\",\"ComplEx\",\"ConvKB\",\"DistMult\",\"TransE\",\"RotatE\",\"R-GCN\"]\n",
    "\n",
    "dataset_names = [ \"Nations\"]\n",
    "final_df = None\n",
    "#models = []\n",
    "output_dir = 'results/'\n",
    "version = 'v05'\n",
    "for dataset in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        print(f\"Running {model_name} on {dataset}\")\n",
    "        df = run_experiment(model_name=model_name, dataset_name=dataset,batch_size=1024, epochs=50, device=\"cuda\", seed=1, n_tests = 5, inference_batch_size=1)\n",
    "        final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        #with open(output_dir + 'model_'+model_name+'_'+dataset+'.pkl', 'wb') as f:\n",
    "        #    pickle.dump(model, f)\n",
    "        #del model\n",
    "        final_df.to_csv(output_dir + 'results_' + version + '.csv', index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2b8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17f570fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>eval_time</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>gpu_mem_avg_MB</th>\n",
       "      <th>gpu_mem_peak_MB</th>\n",
       "      <th>gpu_util_avg_%</th>\n",
       "      <th>gpu_util_peak_%</th>\n",
       "      <th>gpu_power_avg_W</th>\n",
       "      <th>gpu_power_peak_W</th>\n",
       "      <th>gpu_energy_Wh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>55.889957</td>\n",
       "      <td>0.049483</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.388256</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>1838.424915</td>\n",
       "      <td>2151.832031</td>\n",
       "      <td>17.493976</td>\n",
       "      <td>37</td>\n",
       "      <td>10.195176</td>\n",
       "      <td>33.216</td>\n",
       "      <td>0.117528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>57.121391</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.392444</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.465174</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>1834.842898</td>\n",
       "      <td>1845.843750</td>\n",
       "      <td>28.345455</td>\n",
       "      <td>39</td>\n",
       "      <td>9.852670</td>\n",
       "      <td>10.285</td>\n",
       "      <td>0.120422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>56.744441</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.426237</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>1832.942903</td>\n",
       "      <td>1842.906250</td>\n",
       "      <td>26.528037</td>\n",
       "      <td>38</td>\n",
       "      <td>9.479516</td>\n",
       "      <td>9.995</td>\n",
       "      <td>0.112701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>56.815753</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.380729</td>\n",
       "      <td>0.161692</td>\n",
       "      <td>0.460199</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>1833.139165</td>\n",
       "      <td>1841.406250</td>\n",
       "      <td>28.376168</td>\n",
       "      <td>39</td>\n",
       "      <td>9.530516</td>\n",
       "      <td>9.903</td>\n",
       "      <td>0.113307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>57.151320</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.403539</td>\n",
       "      <td>0.196517</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>0.699005</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>1831.398524</td>\n",
       "      <td>1841.593750</td>\n",
       "      <td>27.121413</td>\n",
       "      <td>40</td>\n",
       "      <td>9.590554</td>\n",
       "      <td>10.011</td>\n",
       "      <td>0.120681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>3110.717619</td>\n",
       "      <td>49.950012</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>2422.467026</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>25.473166</td>\n",
       "      <td>100</td>\n",
       "      <td>18.702320</td>\n",
       "      <td>57.506</td>\n",
       "      <td>16.242965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>3098.839153</td>\n",
       "      <td>38.222368</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>2441.924034</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>24.595513</td>\n",
       "      <td>100</td>\n",
       "      <td>19.163355</td>\n",
       "      <td>57.917</td>\n",
       "      <td>16.513489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>3102.416068</td>\n",
       "      <td>45.522542</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>2470.003624</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.102796</td>\n",
       "      <td>100</td>\n",
       "      <td>18.975552</td>\n",
       "      <td>57.016</td>\n",
       "      <td>16.403310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>37</td>\n",
       "      <td>100</td>\n",
       "      <td>3107.673787</td>\n",
       "      <td>45.633842</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>2518.112597</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.203248</td>\n",
       "      <td>100</td>\n",
       "      <td>18.874005</td>\n",
       "      <td>56.580</td>\n",
       "      <td>16.335975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>3111.376637</td>\n",
       "      <td>42.630554</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>2552.145205</td>\n",
       "      <td>11938.617188</td>\n",
       "      <td>24.027760</td>\n",
       "      <td>100</td>\n",
       "      <td>18.707008</td>\n",
       "      <td>57.296</td>\n",
       "      <td>16.191955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model    dataset  seed  epochs   train_time  eval_time  inference_time  \\\n",
       "0   ComplEx    Nations     1     100    55.889957   0.049483        0.000453   \n",
       "1   ComplEx    Nations     2     100    57.121391   0.060622        0.000376   \n",
       "2   ComplEx    Nations     4     100    56.744441   0.049614        0.000455   \n",
       "3   ComplEx    Nations     7     100    56.815753   0.055427        0.000489   \n",
       "4   ComplEx    Nations    11     100    57.151320   0.048009        0.000407   \n",
       "..      ...        ...   ...     ...          ...        ...             ...   \n",
       "75  ComplEx  DBpedia50    16     100  3110.717619  49.950012        0.000423   \n",
       "76  ComplEx  DBpedia50    22     100  3098.839153  38.222368        0.000411   \n",
       "77  ComplEx  DBpedia50    29     100  3102.416068  45.522542        0.000430   \n",
       "78  ComplEx  DBpedia50    37     100  3107.673787  45.633842        0.000401   \n",
       "79  ComplEx  DBpedia50    46     100  3111.376637  42.630554        0.000461   \n",
       "\n",
       "         mrr    hits@1    hits@3    hits@5   hits@10  gpu_mem_avg_MB  \\\n",
       "0   0.388256  0.171642  0.462687  0.681592  0.942786     1838.424915   \n",
       "1   0.392444  0.179104  0.465174  0.691542  0.947761     1834.842898   \n",
       "2   0.426237  0.226368  0.504975  0.691542  0.945274     1832.942903   \n",
       "3   0.380729  0.161692  0.460199  0.701493  0.967662     1833.139165   \n",
       "4   0.403539  0.196517  0.472637  0.699005  0.962687     1831.398524   \n",
       "..       ...       ...       ...       ...       ...             ...   \n",
       "75  0.002023  0.000239  0.001909  0.003103  0.004535     2422.467026   \n",
       "76  0.001632  0.000239  0.001193  0.001671  0.003103     2441.924034   \n",
       "77  0.002852  0.000955  0.002625  0.003819  0.005012     2470.003624   \n",
       "78  0.001730  0.000239  0.001193  0.001909  0.003341     2518.112597   \n",
       "79  0.003281  0.001671  0.002625  0.004057  0.005489     2552.145205   \n",
       "\n",
       "    gpu_mem_peak_MB  gpu_util_avg_%  gpu_util_peak_%  gpu_power_avg_W  \\\n",
       "0       2151.832031       17.493976               37        10.195176   \n",
       "1       1845.843750       28.345455               39         9.852670   \n",
       "2       1842.906250       26.528037               38         9.479516   \n",
       "3       1841.406250       28.376168               39         9.530516   \n",
       "4       1841.593750       27.121413               40         9.590554   \n",
       "..              ...             ...              ...              ...   \n",
       "75     11964.398438       25.473166              100        18.702320   \n",
       "76     11964.398438       24.595513              100        19.163355   \n",
       "77     11958.617188       24.102796              100        18.975552   \n",
       "78     11958.617188       24.203248              100        18.874005   \n",
       "79     11938.617188       24.027760              100        18.707008   \n",
       "\n",
       "    gpu_power_peak_W  gpu_energy_Wh  \n",
       "0             33.216       0.117528  \n",
       "1             10.285       0.120422  \n",
       "2              9.995       0.112701  \n",
       "3              9.903       0.113307  \n",
       "4             10.011       0.120681  \n",
       "..               ...            ...  \n",
       "75            57.506      16.242965  \n",
       "76            57.917      16.513489  \n",
       "77            57.016      16.403310  \n",
       "78            56.580      16.335975  \n",
       "79            57.296      16.191955  \n",
       "\n",
       "[80 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a31b4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('results_nations+db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e344cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pkl', 'wb') as file:\n",
    "    # Use pickle.dump() to serialize the model and save it to the file\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d4b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
