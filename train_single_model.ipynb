{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06749b7",
   "metadata": {},
   "source": [
    "### 1. Framework imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import threading\n",
    "import pynvml\n",
    "\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import get_dataset, dataset_resolver\n",
    "\n",
    "logging.getLogger(\"pykeen\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261de46",
   "metadata": {},
   "source": [
    "### 2. Defining function for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bd602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_monitor(stop_event, interval=1.0, device_index=0, stats=None):\n",
    "    \"\"\"Thread para monitorar consumo de GPU durante o treino.\"\"\"\n",
    "    \n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)\n",
    "    while not stop_event.is_set():\n",
    "        mem = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # W\n",
    "        stats[\"mem_used\"].append(mem.used / 1024**2)  # MB\n",
    "        stats[\"util\"].append(util.gpu)  # %\n",
    "        stats[\"power\"].append(power)  # W\n",
    "        time.sleep(interval)\n",
    "\n",
    "def run_experiment(model_name: str, dataset_name: str, epochs: int = 100,\n",
    "                   batch_size: int = 256, device: str = \"cuda\",\n",
    "                   inference_batch_size: int = 1024, seed: int = 42,\n",
    "                   n_tests: int = 1, verbose: bool = True,\n",
    "                   gpu_index: int = 0, monitor_interval: float = 0.1) -> pd.DataFrame:\n",
    "\n",
    "    metrics = []\n",
    "    models = []\n",
    "    pynvml.nvmlInit()\n",
    "    for i in range(n_tests):\n",
    "        stats = {\"mem_used\": [], \"util\": [], \"power\": []}\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(\n",
    "            target=gpu_monitor, args=(stop_event, monitor_interval, gpu_index, stats)\n",
    "        )\n",
    "        seed = seed + i\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # --- iniciar monitoramento GPU\n",
    "        monitor_thread.start()\n",
    "\n",
    "        # --- Treino + avaliação do PyKEEN\n",
    "        result = pipeline(\n",
    "            model=model_name,\n",
    "            dataset=dataset_name,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            random_seed=seed,\n",
    "            training_kwargs=dict(batch_size=batch_size, sampler=\"schlichtkrull\", use_tqdm_batch=False),use_tqdm=verbose\n",
    "        )\n",
    "\n",
    "        # --- parar monitoramento\n",
    "        stop_event.set()\n",
    "        monitor_thread.join()\n",
    "\n",
    "        # --- estatísticas GPU\n",
    "        avg_mem = sum(stats[\"mem_used\"]) / len(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        peak_mem = max(stats[\"mem_used\"]) if stats[\"mem_used\"] else None\n",
    "        avg_util = sum(stats[\"util\"]) / len(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        peak_util = max(stats[\"util\"]) if stats[\"util\"] else None\n",
    "        avg_power = sum(stats[\"power\"]) / len(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        peak_power = max(stats[\"power\"]) if stats[\"power\"] else None\n",
    "        total_energy_wh = sum(p * monitor_interval for p in stats[\"power\"]) / 3600 if stats[\"power\"] else None\n",
    "\n",
    "        # extrair tempos do pipeline\n",
    "        train_time = getattr(result, \"train_seconds\", None)\n",
    "        eval_time = getattr(result, \"evaluate_seconds\", None)\n",
    "\n",
    "        # métricas do teste\n",
    "        mrr = result.metric_results.get_metric('both.realistic.inverse_harmonic_mean_rank')\n",
    "        hits1 = result.metric_results.get_metric('both.realistic.hits_at_1')\n",
    "        hits3 = result.metric_results.get_metric('both.realistic.hits_at_3')\n",
    "        hits5 = result.metric_results.get_metric('both.realistic.hits_at_5')\n",
    "        hits10 = result.metric_results.get_metric('both.realistic.hits_at_10')\n",
    "\n",
    "         # --- Tempo de inferência pura\n",
    "        dataset = dataset_resolver.lookup(dataset_name)()\n",
    "        triples = dataset.testing.mapped_triples\n",
    "        n_test = int(triples.shape[0]) if hasattr(triples, \"shape\") else len(triples)\n",
    "\n",
    "        model = result.model\n",
    "        device_torch = model.device\n",
    "        # CONVERSÃO ROBUSTA:\n",
    "        if isinstance(triples, torch.Tensor):\n",
    "            triples_tensor = triples.to(device=device_torch, dtype=torch.long)\n",
    "        else:\n",
    "            # as_tensor evita cópia se já for tensor; em numpy -> cria tensor\n",
    "            triples_tensor = torch.as_tensor(triples, dtype=torch.long)\n",
    "            triples_tensor = triples_tensor.to(device=device_torch)\n",
    "\n",
    "        # inferência\n",
    "        with torch.inference_mode():\n",
    "            infer_t0 = time.perf_counter()\n",
    "            for j in range(0, n_test, inference_batch_size):   # use 'j' para não conflitar\n",
    "                batch = triples_tensor[j:j+inference_batch_size]\n",
    "                _ = model.score_hrt(batch)\n",
    "            # sincroniza só se CUDA\n",
    "            if device_torch.type == \"cuda\" and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize(device_torch)\n",
    "            infer_t1 = time.perf_counter()\n",
    "\n",
    "        infer_time = (infer_t1 - infer_t0) / n_test if n_test else None\n",
    "\n",
    "        # --- montar resultado em forma de DataFrame (1 linha)\n",
    "        df = pd.DataFrame([{\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"seed\": seed,\n",
    "            \"epochs\": epochs,\n",
    "            \"train_time\": train_time,\n",
    "            \"eval_time\": eval_time,\n",
    "            \"inference_time\": infer_time,\n",
    "            \"mrr\": mrr,\n",
    "            \"hits@1\": hits1,\n",
    "            \"hits@3\": hits3,\n",
    "            \"hits@5\": hits5,\n",
    "            \"hits@10\": hits10,\n",
    "            \"gpu_mem_avg_MB\": avg_mem,\n",
    "            \"gpu_mem_peak_MB\": peak_mem,\n",
    "            \"gpu_util_avg_%\": avg_util,\n",
    "            \"gpu_util_peak_%\": peak_util,\n",
    "            \"gpu_power_avg_W\": avg_power,\n",
    "            \"gpu_power_peak_W\": peak_power,\n",
    "            \"gpu_energy_Wh\": total_energy_wh,\n",
    "        }])\n",
    "        metrics.append(df)\n",
    "        models.append(result)\n",
    "    pynvml.nvmlShutdown()\n",
    "        \n",
    "        \n",
    "    return pd.concat(metrics, ignore_index=True), models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db96e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a22fe34cbf24047a9f850b004d3e68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df, models = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConvKB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDBpedia50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, device, inference_batch_size, seed, n_tests, verbose, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     33\u001b[39m monitor_thread.start()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschlichtkrull\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     46\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1540\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1519\u001b[39m training_loop_instance = _handle_training_loop(\n\u001b[32m   1520\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1521\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m     negative_sampler_kwargs=negative_sampler_kwargs,\n\u001b[32m   1531\u001b[39m )\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m stopper_instance, configuration, losses, train_seconds = \u001b[43m_handle_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m metric_results, evaluate_seconds = _handle_evaluation(\n\u001b[32m   1557\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1558\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1569\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1570\u001b[39m )\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1181\u001b[39m, in \u001b[36m_handle_training\u001b[39m\u001b[34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001b[39m\n\u001b[32m   1179\u001b[39m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[32m   1180\u001b[39m training_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m losses = \u001b[43mtraining_loop_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[32m   1188\u001b[39m training_end_time = time.time() - training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:383\u001b[39m, in \u001b[36mTrainingLoop.train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    380\u001b[39m             temporary_directory = exit_stack.enter_context(TemporaryDirectory())\n\u001b[32m    381\u001b[39m             best_epoch_model_file_path = pathlib.Path(temporary_directory).joinpath(\u001b[33m\"\u001b[39m\u001b[33mbest_model.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[32m    414\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:707\u001b[39m, in \u001b[36mTrainingLoop._train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     batches = train_data_loader\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m epoch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;66;03m# When size probing we don't need the losses\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:453\u001b[39m, in \u001b[36mTrainingLoop._train_epoch\u001b[39m\u001b[34m(self, batches, callbacks, sub_batch_size, label_smoothing, slice_size, epoch, only_size_probing, backward)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Flag to check when to quit the size probing\u001b[39;00m\n\u001b[32m    451\u001b[39m evaluated_once = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# apply callbacks before starting with batch\u001b[39;49;00m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Get batch size of current batch (last batch may be incomplete)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:152\u001b[39m, in \u001b[36mBaseBatchedSLCWAInstances.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[SLCWABatch]:\n\u001b[32m    151\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over batches.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_triple_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.iter_triple_ids\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.subgraph_sample() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubgraph_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:228\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.subgraph_sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# normalize to probabilities\u001b[39;00m\n\u001b[32m    227\u001b[39m     probabilities = weights.float() / weights.sum().float()\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     chosen_vertex = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# sample a start node\u001b[39;00m\n\u001b[32m    231\u001b[39m node_picked[chosen_vertex] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df, models = run_experiment(model_name=\"ConvKB\", dataset_name=\"DBpedia50\", epochs=100, device=\"cuda\", seed=1, n_tests = 1, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c8cd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9838bea04f40bc8bc867cd4175713e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exemplo de uso\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df, models = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mConvE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDBpedia50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(model_name, dataset_name, epochs, batch_size, device, inference_batch_size, seed, n_tests, verbose, gpu_index, monitor_interval)\u001b[39m\n\u001b[32m     33\u001b[39m monitor_thread.start()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# --- Treino + avaliação do PyKEEN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m result = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschlichtkrull\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- parar monitoramento\u001b[39;00m\n\u001b[32m     46\u001b[39m stop_event.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1540\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001b[39m\n\u001b[32m   1519\u001b[39m training_loop_instance = _handle_training_loop(\n\u001b[32m   1520\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1521\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m     negative_sampler_kwargs=negative_sampler_kwargs,\n\u001b[32m   1531\u001b[39m )\n\u001b[32m   1533\u001b[39m evaluator_instance, evaluation_kwargs = _handle_evaluator(\n\u001b[32m   1534\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1535\u001b[39m     evaluator=evaluator,\n\u001b[32m   1536\u001b[39m     evaluator_kwargs=evaluator_kwargs,\n\u001b[32m   1537\u001b[39m     evaluation_kwargs=evaluation_kwargs,\n\u001b[32m   1538\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m stopper_instance, configuration, losses, train_seconds = \u001b[43m_handle_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_result_tracker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_loop_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m metric_results, evaluate_seconds = _handle_evaluation(\n\u001b[32m   1557\u001b[39m     _result_tracker=_result_tracker,\n\u001b[32m   1558\u001b[39m     model_instance=model_instance,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1569\u001b[39m     use_tqdm=use_tqdm,\n\u001b[32m   1570\u001b[39m )\n\u001b[32m   1571\u001b[39m _result_tracker.end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\pipeline\\api.py:1181\u001b[39m, in \u001b[36m_handle_training\u001b[39m\u001b[34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001b[39m\n\u001b[32m   1179\u001b[39m \u001b[38;5;66;03m# Train like Cristiano Ronaldo\u001b[39;00m\n\u001b[32m   1180\u001b[39m training_start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m losses = \u001b[43mtraining_loop_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclear_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# losses is only none if it's doing search mode\u001b[39;00m\n\u001b[32m   1188\u001b[39m training_end_time = time.time() - training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:383\u001b[39m, in \u001b[36mTrainingLoop.train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    380\u001b[39m             temporary_directory = exit_stack.enter_context(TemporaryDirectory())\n\u001b[32m    381\u001b[39m             best_epoch_model_file_path = pathlib.Path(temporary_directory).joinpath(\u001b[33m\"\u001b[39m\u001b[33mbest_model.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_on_failure_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_epoch_model_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_best_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_norm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_clipping_max_abs_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtriples_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Ensure the release of memory\u001b[39;00m\n\u001b[32m    414\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:707\u001b[39m, in \u001b[36mTrainingLoop._train\u001b[39m\u001b[34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callbacks_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    705\u001b[39m     batches = train_data_loader\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m epoch_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_size_probing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;66;03m# When size probing we don't need the losses\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m only_size_probing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\training\\training_loop.py:453\u001b[39m, in \u001b[36mTrainingLoop._train_epoch\u001b[39m\u001b[34m(self, batches, callbacks, sub_batch_size, label_smoothing, slice_size, epoch, only_size_probing, backward)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Flag to check when to quit the size probing\u001b[39;00m\n\u001b[32m    451\u001b[39m evaluated_once = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# apply callbacks before starting with batch\u001b[39;49;00m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Get batch size of current batch (last batch may be incomplete)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:152\u001b[39m, in \u001b[36mBaseBatchedSLCWAInstances.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[SLCWABatch]:\n\u001b[32m    151\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over batches.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_triple_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtriple_ids\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.iter_triple_ids\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.subgraph_sample() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:262\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miter_triple_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubgraph_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m split_workload(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\grkremer\\miniconda3\\Lib\\site-packages\\pykeen\\triples\\instances.py:221\u001b[39m, in \u001b[36mSubGraphSLCWAInstances.subgraph_sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.batch_size):\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# determine weights\u001b[39;00m\n\u001b[32m    219\u001b[39m     weights = node_weights * node_picked\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m == \u001b[32m0\u001b[39m:\n\u001b[32m    222\u001b[39m         \u001b[38;5;66;03m# randomly choose a vertex which has not been chosen yet\u001b[39;00m\n\u001b[32m    223\u001b[39m         pool = (~node_picked).nonzero()\n\u001b[32m    224\u001b[39m         chosen_vertex = pool[torch.randint(pool.numel(), size=\u001b[38;5;28mtuple\u001b[39m())]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "df, models = run_experiment(model_name=\"ConvE\", dataset_name=\"DBpedia50\", epochs=100, device=\"cuda\", seed=1, n_tests = 5, inference_batch_size=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcde904",
   "metadata": {},
   "source": [
    "### 3. Definir modelos e datasets a serem avaliados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8463107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ConvE on DBpedia50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e20ed8210f449c38ff2f05a0df7dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed724f4cc341eabb3997211dd599f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/2.10k [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"ConvE\",\"ConvKB\",\"DistMult\",\"TransE\",\"RotatE\",\"R-GCN\"]\n",
    "\n",
    "dataset_names = [ \"DBpedia50\"]\n",
    "final_df = None\n",
    "models = []\n",
    "output_dir = 'results/'\n",
    "version = 'v03'\n",
    "for dataset in dataset_names:\n",
    "    for model_name in model_names:\n",
    "        print(f\"Running {model_name} on {dataset}\")\n",
    "        df, model = run_experiment(model_name=model_name, dataset_name=dataset,batch_size=1024, epochs=1, device=\"cuda\", seed=1, n_tests = 5, inference_batch_size=1)\n",
    "        final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "        with open(output_dir + 'model_'+model_name+'_'+dataset+'.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        del model\n",
    "        final_df.to_csv(output_dir + 'results_' + version + '.csv', index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17f570fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>seed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time</th>\n",
       "      <th>eval_time</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits@1</th>\n",
       "      <th>hits@3</th>\n",
       "      <th>hits@5</th>\n",
       "      <th>hits@10</th>\n",
       "      <th>gpu_mem_avg_MB</th>\n",
       "      <th>gpu_mem_peak_MB</th>\n",
       "      <th>gpu_util_avg_%</th>\n",
       "      <th>gpu_util_peak_%</th>\n",
       "      <th>gpu_power_avg_W</th>\n",
       "      <th>gpu_power_peak_W</th>\n",
       "      <th>gpu_energy_Wh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>55.889957</td>\n",
       "      <td>0.049483</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.388256</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>0.942786</td>\n",
       "      <td>1838.424915</td>\n",
       "      <td>2151.832031</td>\n",
       "      <td>17.493976</td>\n",
       "      <td>37</td>\n",
       "      <td>10.195176</td>\n",
       "      <td>33.216</td>\n",
       "      <td>0.117528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>57.121391</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.392444</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.465174</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.947761</td>\n",
       "      <td>1834.842898</td>\n",
       "      <td>1845.843750</td>\n",
       "      <td>28.345455</td>\n",
       "      <td>39</td>\n",
       "      <td>9.852670</td>\n",
       "      <td>10.285</td>\n",
       "      <td>0.120422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>56.744441</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.426237</td>\n",
       "      <td>0.226368</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.945274</td>\n",
       "      <td>1832.942903</td>\n",
       "      <td>1842.906250</td>\n",
       "      <td>26.528037</td>\n",
       "      <td>38</td>\n",
       "      <td>9.479516</td>\n",
       "      <td>9.995</td>\n",
       "      <td>0.112701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>56.815753</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.380729</td>\n",
       "      <td>0.161692</td>\n",
       "      <td>0.460199</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>1833.139165</td>\n",
       "      <td>1841.406250</td>\n",
       "      <td>28.376168</td>\n",
       "      <td>39</td>\n",
       "      <td>9.530516</td>\n",
       "      <td>9.903</td>\n",
       "      <td>0.113307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>Nations</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>57.151320</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.403539</td>\n",
       "      <td>0.196517</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>0.699005</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>1831.398524</td>\n",
       "      <td>1841.593750</td>\n",
       "      <td>27.121413</td>\n",
       "      <td>40</td>\n",
       "      <td>9.590554</td>\n",
       "      <td>10.011</td>\n",
       "      <td>0.120681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>3110.717619</td>\n",
       "      <td>49.950012</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>2422.467026</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>25.473166</td>\n",
       "      <td>100</td>\n",
       "      <td>18.702320</td>\n",
       "      <td>57.506</td>\n",
       "      <td>16.242965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>3098.839153</td>\n",
       "      <td>38.222368</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>2441.924034</td>\n",
       "      <td>11964.398438</td>\n",
       "      <td>24.595513</td>\n",
       "      <td>100</td>\n",
       "      <td>19.163355</td>\n",
       "      <td>57.917</td>\n",
       "      <td>16.513489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>3102.416068</td>\n",
       "      <td>45.522542</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>2470.003624</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.102796</td>\n",
       "      <td>100</td>\n",
       "      <td>18.975552</td>\n",
       "      <td>57.016</td>\n",
       "      <td>16.403310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>37</td>\n",
       "      <td>100</td>\n",
       "      <td>3107.673787</td>\n",
       "      <td>45.633842</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>2518.112597</td>\n",
       "      <td>11958.617188</td>\n",
       "      <td>24.203248</td>\n",
       "      <td>100</td>\n",
       "      <td>18.874005</td>\n",
       "      <td>56.580</td>\n",
       "      <td>16.335975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ComplEx</td>\n",
       "      <td>DBpedia50</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>3111.376637</td>\n",
       "      <td>42.630554</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>2552.145205</td>\n",
       "      <td>11938.617188</td>\n",
       "      <td>24.027760</td>\n",
       "      <td>100</td>\n",
       "      <td>18.707008</td>\n",
       "      <td>57.296</td>\n",
       "      <td>16.191955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model    dataset  seed  epochs   train_time  eval_time  inference_time  \\\n",
       "0   ComplEx    Nations     1     100    55.889957   0.049483        0.000453   \n",
       "1   ComplEx    Nations     2     100    57.121391   0.060622        0.000376   \n",
       "2   ComplEx    Nations     4     100    56.744441   0.049614        0.000455   \n",
       "3   ComplEx    Nations     7     100    56.815753   0.055427        0.000489   \n",
       "4   ComplEx    Nations    11     100    57.151320   0.048009        0.000407   \n",
       "..      ...        ...   ...     ...          ...        ...             ...   \n",
       "75  ComplEx  DBpedia50    16     100  3110.717619  49.950012        0.000423   \n",
       "76  ComplEx  DBpedia50    22     100  3098.839153  38.222368        0.000411   \n",
       "77  ComplEx  DBpedia50    29     100  3102.416068  45.522542        0.000430   \n",
       "78  ComplEx  DBpedia50    37     100  3107.673787  45.633842        0.000401   \n",
       "79  ComplEx  DBpedia50    46     100  3111.376637  42.630554        0.000461   \n",
       "\n",
       "         mrr    hits@1    hits@3    hits@5   hits@10  gpu_mem_avg_MB  \\\n",
       "0   0.388256  0.171642  0.462687  0.681592  0.942786     1838.424915   \n",
       "1   0.392444  0.179104  0.465174  0.691542  0.947761     1834.842898   \n",
       "2   0.426237  0.226368  0.504975  0.691542  0.945274     1832.942903   \n",
       "3   0.380729  0.161692  0.460199  0.701493  0.967662     1833.139165   \n",
       "4   0.403539  0.196517  0.472637  0.699005  0.962687     1831.398524   \n",
       "..       ...       ...       ...       ...       ...             ...   \n",
       "75  0.002023  0.000239  0.001909  0.003103  0.004535     2422.467026   \n",
       "76  0.001632  0.000239  0.001193  0.001671  0.003103     2441.924034   \n",
       "77  0.002852  0.000955  0.002625  0.003819  0.005012     2470.003624   \n",
       "78  0.001730  0.000239  0.001193  0.001909  0.003341     2518.112597   \n",
       "79  0.003281  0.001671  0.002625  0.004057  0.005489     2552.145205   \n",
       "\n",
       "    gpu_mem_peak_MB  gpu_util_avg_%  gpu_util_peak_%  gpu_power_avg_W  \\\n",
       "0       2151.832031       17.493976               37        10.195176   \n",
       "1       1845.843750       28.345455               39         9.852670   \n",
       "2       1842.906250       26.528037               38         9.479516   \n",
       "3       1841.406250       28.376168               39         9.530516   \n",
       "4       1841.593750       27.121413               40         9.590554   \n",
       "..              ...             ...              ...              ...   \n",
       "75     11964.398438       25.473166              100        18.702320   \n",
       "76     11964.398438       24.595513              100        19.163355   \n",
       "77     11958.617188       24.102796              100        18.975552   \n",
       "78     11958.617188       24.203248              100        18.874005   \n",
       "79     11938.617188       24.027760              100        18.707008   \n",
       "\n",
       "    gpu_power_peak_W  gpu_energy_Wh  \n",
       "0             33.216       0.117528  \n",
       "1             10.285       0.120422  \n",
       "2              9.995       0.112701  \n",
       "3              9.903       0.113307  \n",
       "4             10.011       0.120681  \n",
       "..               ...            ...  \n",
       "75            57.506      16.242965  \n",
       "76            57.917      16.513489  \n",
       "77            57.016      16.403310  \n",
       "78            56.580      16.335975  \n",
       "79            57.296      16.191955  \n",
       "\n",
       "[80 rows x 19 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a31b4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('results_nations+db.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e344cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pkl', 'wb') as file:\n",
    "    # Use pickle.dump() to serialize the model and save it to the file\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d4b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
